from dataclasses import dataclass
from typing import List, Optional, Union

import torch

from megatron.core.packed_seq_params import PackedSeqParams

from d2.runtime.metadata import AlltoAllMetadata


def _to_cuda_int32(tensor: Optional[torch.Tensor]):
    if tensor is None:
        return None
    return tensor.cuda().to(torch.int32).contiguous()


def _to_int(tensor):
    if isinstance(tensor, torch.Tensor):
        return tensor.cpu().item()
    assert isinstance(tensor, int), f"Must be int. Current type: {type(tensor)}"
    return tensor


@dataclass
class PingPangSingleStepPackedSeqParams(PackedSeqParams):
    qkv_fwd_metadata: AlltoAllMetadata = None
    qkv_bwd_metadata: AlltoAllMetadata = None
    attn_out_fwd_metadata: AlltoAllMetadata = None
    attn_out_bwd_metadata: AlltoAllMetadata = None
    bwd_packed_seq_params: PackedSeqParams = None
    stream: torch.cuda.Stream = None
    dispatcher_id: int = None
    #### DEBUG members. Should be None
    # TODO: remove it by redesigning test files.
    mlp_packed_seq_params: PackedSeqParams = None

    def to_device(self):
        return PingPangSingleStepPackedSeqParams(
            qkv_format=self.qkv_format,
            cu_seqlens_q=_to_cuda_int32(self.cu_seqlens_q),
            cu_seqlens_kv=_to_cuda_int32(self.cu_seqlens_kv),
            cu_seqlens_q_padded=_to_cuda_int32(self.cu_seqlens_q_padded),
            cu_seqlens_kv_padded=_to_cuda_int32(self.cu_seqlens_kv_padded),
            max_seqlen_q=_to_int(self.max_seqlen_q),
            max_seqlen_kv=_to_int(self.max_seqlen_kv),
            qkv_fwd_metadata=self.qkv_fwd_metadata.normalize(),
            qkv_bwd_metadata=self.qkv_bwd_metadata.normalize(),
            attn_out_fwd_metadata=self.attn_out_fwd_metadata.normalize(),
            attn_out_bwd_metadata=self.attn_out_bwd_metadata.normalize(),
            bwd_packed_seq_params=arg_to_cuda(self.bwd_packed_seq_params),
            stream=self.stream,
            dispatcher_id=self.dispatcher_id,
            mlp_packed_seq_params=arg_to_cuda(self.mlp_packed_seq_params),
        )


@dataclass
class PingPangPackedSeqParams:
    seq_params: List[PingPangSingleStepPackedSeqParams]
    # The seq params for mlp layout. This is mainly used for the RoPE.
    mlp_layout_seq_params: List[PackedSeqParams]
    # NOTE: within a TransformerLayer, this will make sure all communications run on the compute stream.
    debug: bool = False
    do_gather: bool = False
    # NOTE: These attributes are used for rotary seq len's max length.
    # since we do rope in the MLP layout, it should be the max length
    # at the MLP layout (i.e. the number of tokens).
    max_seqlen_q: Optional[Union[torch.Tensor, int]] = None
    max_seqlen_kv: Optional[Union[torch.Tensor, int]] = None
    qkv_format: str = "thd"

    def to_device(self):

        max_seqlen_q = self.max_seqlen_q
        if max_seqlen_q is None:
            max_seqlen_q = max([p.max_seqlen_q for p in self.mlp_layout_seq_params])
        max_seqlen_kv = self.max_seqlen_kv
        if max_seqlen_kv is None:
            max_seqlen_kv = max([p.max_seqlen_kv for p in self.mlp_layout_seq_params])
        return PingPangPackedSeqParams(
            seq_params=[seq_param.to_device() for seq_param in self.seq_params],
            mlp_layout_seq_params=[
                arg_to_cuda(seq_param) for seq_param in self.mlp_layout_seq_params
            ],
            debug=self.debug,
            do_gather=self.do_gather,
            max_seqlen_q=_to_int(max_seqlen_q),
            max_seqlen_kv=_to_int(max_seqlen_kv),
        )


def arg_to_cuda(v):
    if v is None:
        return None
    if isinstance(v, torch.Tensor):
        return v.cuda()
    elif isinstance(v, PingPangPackedSeqParams):
        return v.to_device()
    elif isinstance(v, PingPangSingleStepPackedSeqParams):
        return v.to_device()
    elif isinstance(v, PackedSeqParams):
        return PackedSeqParams(
            qkv_format=v.qkv_format,
            cu_seqlens_q=_to_cuda_int32(v.cu_seqlens_q),
            cu_seqlens_kv=_to_cuda_int32(v.cu_seqlens_kv),
            max_seqlen_q=_to_int(v.max_seqlen_q),
            max_seqlen_kv=_to_int(v.max_seqlen_kv),
            cu_seqlens_q_padded=_to_cuda_int32(v.cu_seqlens_q_padded),
            cu_seqlens_kv_padded=_to_cuda_int32(v.cu_seqlens_kv_padded),
        )
    return v
