MLP testing context length: 1024
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   0.251 ms     0.00 M
model.layers.0.self_attn.q_proj                  0.459 ms    33.55 M
model.layers.0.self_attn.q_norm                  0.363 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.095 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.192 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.092 ms     2.10 M
model.layers.0.self_attn.o_proj                  0.586 ms    33.55 M
model.layers.0.post_attention_layernorm          0.207 ms     0.00 M
model.layers.0.mlp.gate                          0.075 ms     0.52 M
model.layers.0.*expert*                         21.295 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 1024
total layer 0 time: 23.614 ms
full forward time: 60.825 ms
layer 0 time: 23.614 ms
total time: 60.825 ms

MLP testing context length: 2048
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   0.357 ms     0.00 M
model.layers.0.self_attn.q_proj                  0.717 ms    33.55 M
model.layers.0.self_attn.q_norm                  0.632 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.123 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.174 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.120 ms     2.10 M
model.layers.0.self_attn.o_proj                  1.691 ms    33.55 M
model.layers.0.post_attention_layernorm          0.359 ms     0.00 M
model.layers.0.mlp.gate                          0.080 ms     0.52 M
model.layers.0.*expert*                         22.591 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 2048
total layer 0 time: 26.846 ms
full forward time: 70.522 ms
layer 0 time: 26.846 ms
total time: 70.522 ms

MLP testing context length: 4096
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   0.580 ms     0.00 M
model.layers.0.self_attn.q_proj                  1.100 ms    33.55 M
model.layers.0.self_attn.q_norm                  1.073 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.148 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.196 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.145 ms     2.10 M
model.layers.0.self_attn.o_proj                  3.514 ms    33.55 M
model.layers.0.post_attention_layernorm          0.599 ms     0.00 M
model.layers.0.mlp.gate                          0.092 ms     0.52 M
model.layers.0.*expert*                         24.943 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 4096
total layer 0 time: 32.390 ms
full forward time: 85.180 ms
layer 0 time: 32.390 ms
total time: 85.180 ms

MLP testing context length: 8192
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   1.072 ms     0.00 M
model.layers.0.self_attn.q_proj                  1.987 ms    33.55 M
model.layers.0.self_attn.q_norm                  2.044 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.259 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.199 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.258 ms     2.10 M
model.layers.0.self_attn.o_proj                  9.740 ms    33.55 M
model.layers.0.post_attention_layernorm          1.166 ms     0.00 M
model.layers.0.mlp.gate                          0.125 ms     0.52 M
model.layers.0.*expert*                         30.835 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 8192
total layer 0 time: 47.684 ms
full forward time: 122.633 ms
layer 0 time: 47.684 ms
total time: 122.633 ms

MLP testing context length: 16384
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   2.045 ms     0.00 M
model.layers.0.self_attn.q_proj                  3.961 ms    33.55 M
model.layers.0.self_attn.q_norm                  4.015 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.365 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.327 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.363 ms     2.10 M
model.layers.0.self_attn.o_proj                 30.143 ms    33.55 M
model.layers.0.post_attention_layernorm          2.295 ms     0.00 M
model.layers.0.mlp.gate                          0.176 ms     0.52 M
model.layers.0.*expert*                         43.215 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 16384
total layer 0 time: 86.905 ms
full forward time: 208.010 ms
layer 0 time: 86.905 ms
total time: 208.010 ms

MLP testing context length: 32768
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   3.999 ms     0.00 M
model.layers.0.self_attn.q_proj                  7.852 ms    33.55 M
model.layers.0.self_attn.q_norm                  7.939 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.574 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.579 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.572 ms     2.10 M
model.layers.0.self_attn.o_proj                102.060 ms    33.55 M
model.layers.0.post_attention_layernorm          4.549 ms     0.00 M
model.layers.0.mlp.gate                          0.336 ms     0.52 M
model.layers.0.*expert*                         67.285 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 32768
total layer 0 time: 195.744 ms
full forward time: 411.227 ms
layer 0 time: 195.744 ms
total time: 411.227 ms

MLP testing context length: 49152
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   5.961 ms     0.00 M
model.layers.0.self_attn.q_proj                 11.672 ms    33.55 M
model.layers.0.self_attn.q_norm                 11.852 ms     0.00 M
model.layers.0.self_attn.k_proj                  0.874 ms     2.10 M
model.layers.0.self_attn.k_norm                  0.823 ms     0.00 M
model.layers.0.self_attn.v_proj                  0.870 ms     2.10 M
model.layers.0.self_attn.o_proj                220.056 ms    33.55 M
model.layers.0.post_attention_layernorm          6.793 ms     0.00 M
model.layers.0.mlp.gate                          0.412 ms     0.52 M
model.layers.0.*expert*                         90.660 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 49152
total layer 0 time: 349.971 ms
full forward time: 660.024 ms
layer 0 time: 349.971 ms
total time: 660.024 ms

MLP testing context length: 65536
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                   7.913 ms     0.00 M
model.layers.0.self_attn.q_proj                 15.594 ms    33.55 M
model.layers.0.self_attn.q_norm                 15.780 ms     0.00 M
model.layers.0.self_attn.k_proj                  1.088 ms     2.10 M
model.layers.0.self_attn.k_norm                  1.069 ms     0.00 M
model.layers.0.self_attn.v_proj                  1.080 ms     2.10 M
model.layers.0.self_attn.o_proj                381.365 ms    33.55 M
model.layers.0.post_attention_layernorm          9.077 ms     0.00 M
model.layers.0.mlp.gate                          0.508 ms     0.52 M
model.layers.0.*expert*                        114.411 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 65536
total layer 0 time: 547.884 ms
full forward time: 951.984 ms
layer 0 time: 547.884 ms
total time: 951.984 ms

MLP testing context length: 98304
module                                         latency  params
----------------------------------------------------------------------
model.layers.0.input_layernorm                  11.849 ms     0.00 M
model.layers.0.self_attn.q_proj                 23.518 ms    33.55 M
model.layers.0.self_attn.q_norm                 23.735 ms     0.00 M
model.layers.0.self_attn.k_proj                  1.768 ms     2.10 M
model.layers.0.self_attn.k_norm                  1.627 ms     0.00 M
model.layers.0.self_attn.v_proj                  1.598 ms     2.10 M
model.layers.0.self_attn.o_proj                843.236 ms    33.55 M
model.layers.0.post_attention_layernorm         13.624 ms     0.00 M
model.layers.0.mlp.gate                          0.748 ms     0.52 M
model.layers.0.*expert*                        160.859 ms  2415.92 M
----------------------------------------------------------------------
model: Qwen/Qwen3-235B-A22B
device: H100
ctx_len: 98304
total layer 0 time: 1082.563 ms
full forward time: 1676.458 ms
layer 0 time: 1082.563 ms
total time: 1676.458 ms
